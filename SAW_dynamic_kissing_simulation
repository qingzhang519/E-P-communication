# -*- coding: utf-8 -*-
"""
The simulation for E-P dynamic kissing model. 
"""
globals().clear() 
import numpy as np
import matplotlib.pyplot as plt
import time
import math
import xlsxwriter
import pandas as pd
import os
import gc

plt.close('all')
gc.collect()  # 强制垃圾回收

import SAW_pivot_spherical_surface_partialconfinement_ChenData as SAW_walk


Walk=SAW_walk.Walk 

N_step = Walk.shape[0]
N_run = Walk.shape[2]

#N_step=397;

L_linker=3*1e-3;  #  nm->um
d_linker=1*L_linker;
L_nc=50*1e-3;  # nm->um
d_nc=10*1e-3;  # nm->um

d_bead=d_nc+d_linker;
L_bead=L_nc+L_linker;

L_EP=7.48; # um;  

dt=0.05*2; 
lambda_P_a=0.3;
lambda_P_i=0.11;
lambda_E_i=0.14; 
g=1; 
Ec=5;  Ec_low=0;

repeat = 1
np.random.seed(repeat)  

current_dir = os.path.dirname(os.path.abspath('SAW_dynamic_kissing_simulation.py'))
sdir=current_dir+'/data/'
sfilename=f"Analysis_Gregor-Ec={Ec}-{Ec_low};g={g}-4.xlsx";


n = int(L_EP // L_bead) + 1  
# Ensure n is even
if n % 2 != 0:  # 
    n += 1

L_scaled = n  # bead number
r = d_bead    # bead size

n2 = 3
n3 = N_run
m = n3 - 5000  
range_begin = np.arange(50, N_step - 50 - L_scaled + 1, 50)  # +1 to include last value

End2 = np.zeros((len(range_begin), n2, m))
start_time = time.time()
End2 = Walk[range_begin + L_scaled, :, -m:] - Walk[range_begin, :, -m:]
print(f"Calculation time: {time.time() - start_time:.4f} seconds")
R_end2 = np.sqrt(np.sum(End2**2, axis=1))
R_end3=R_end2 ########

output_filename = 'SAW_shere_surface.xlsx'
with xlsxwriter.Workbook(output_filename) as workbook:
    worksheet = workbook.add_worksheet()
    for row in range(R_end3.shape[0]):
        worksheet.write_row(row, 0, R_end3[row, :])

R_end = R_end3.flatten()
R_end=R_end*r;
d_c=np.mean(R_end)-np.std(R_end)*1; 

# Randomly produce the promoter active and inactive states
tt = np.zeros(int(1e6))
TT = np.zeros(int(1e6))
pp = np.random.rand(int(1e6))

for i in range(len(pp)):
    p = pp[i]
    if (i + 1) % 2 == 0:  
        lambda0 = lambda_P_i
    else:
        lambda0 = lambda_P_a
    
    tt[i] = -np.log(1 - p) / lambda0
    
    if i == 0:
        TT[i] = tt[i]
    else:
        TT[i] = TT[i-1] + tt[i]
    
    if TT[i] > len(R_end) * dt:
        i = i - 1
        break

TT2 = np.floor(TT[:i+1] / dt).astype(int)

K_P_a = TT2[::2]  # points where the promoter is activated by signal 1

TT2 = np.append(TT2, len(R_end))
J2 = np.zeros(len(R_end))

for i in range(0, len(TT2)-1, 2):
    start_idx = TT2[i] + 1
    end_idx = TT2[i+1]
    if start_idx < len(J2):
        end_idx = min(end_idx, len(J2)-1)
        J2[start_idx:end_idx+1] = 1  # active promoter points

print("Size of J2:", J2.shape)

# Test the simulation by comparing the duration of promoter licensed
plt.figure(101)
diff_J2 = np.diff(J2)
K_activate2 = np.where(diff_J2 == 1)[0]
K_inactivate2 = np.where(diff_J2 == -1)[0]

if len(K_activate2) == len(K_inactivate2):
    T_promoter_active = K_inactivate2 - K_activate2
else:
    T_promoter_active = K_inactivate2[:len(K_activate2)] - K_activate2[:-1]

T = T_promoter_active * dt
bins = np.arange(0, 50.5, 1)  
fx, x = np.histogram(T, bins=bins)
px = fx / np.sum(fx) / (bins[1] - bins[0])

plt.plot(x[:-1], px, 'ok', linewidth=2)

tt = np.arange(0, 100.01, 0.01)
lambda_val = lambda_P_i
yy = lambda_val * np.exp(-lambda_val * tt)

plt.plot(tt, yy, '-g', linewidth=2)
plt.legend(['Simulation', 'Simple model'],fontsize=12)
plt.ylabel('PDF',fontsize=12)
plt.xlabel('Duration of promoter licensed (min)',fontsize=12)
plt.xlim([0, 40])
#plt.gca().set_fontsize(12)
plt.show()


## define the enhancer action states by the E-P distance + some special signal 
# Initial enhancer-promoter interaction state
I = (R_end < d_c)
J1 = I.copy()

# Setup
tt = []
TT = []
pp = np.random.rand(2000)

I1 = np.where(I)[0]
if len(I1) == 0:
    raise ValueError("No initial enhancer-promoter interaction detected.")
TT.append((I1[0] - 1) * dt)

ii = np.where(~I[int(TT[0]/dt)+1:])[0]
if len(ii) == 0:
    TT.append(len(R_end) * dt)
else:
    TT.append(TT[0] + ii[0] * dt)
i = 2
while TT[-1] <= len(R_end) * dt:
    i += 1
    lambda0 = lambda_E_i
    p = np.random.rand()
    t_wait = -np.log(1 - p) / lambda0
    i_r = int((TT[i-2] + t_wait) / dt)
    
    if i_r >= len(R_end):
        TT[i-2] = len(R_end) * dt
        break

    if R_end[i_r] < d_c:
        ii = np.where(~I[i_r+1:])[0]
        if len(ii) == 0:
            TT[i-2] = len(R_end) * dt
            break
        J1[int(TT[i-2]/dt):i_r + ii[0]] = 1
        TT[i-2] = (i_r + ii[0]) * dt
        i -= 1
    else:
        # Newly added part for burst duration calculation
        J1[int(TT[i-2]/dt):i_r+1] = 1
        TT[i-2] = i_r * dt
        ii = np.where(I[i_r+1:])[0]
        if len(ii) == 0:
            TT.append(len(R_end) * dt)
            break
        TT.append(TT[i-2] + ii[0] * dt)

        ii = np.where(~I[int(TT[i-1]/dt)+1:])[0]
        if len(ii) > 0:
            TT.append(TT[i-1] + ii[0] * dt)
            i += 1
        else:
            TT.append(len(R_end) * dt)
            break

TT2 = np.array(TT) / dt
TT2 = np.floor(TT2).astype(int)
K_E_a = TT2[::2]  # Points where promoter is activated

# Analyzing promoter activation durations
K_activate1 = np.where(np.diff(J1.astype(int)) == 1)[0]
K_inactivate1 = np.where(np.diff(J1.astype(int)) == -1)[0]

if len(K_activate1) == len(K_inactivate1):
    T_promoter_active = K_inactivate1 - K_activate1
else:
    T_promoter_active = K_inactivate1[:len(K_activate1)] - K_activate1[:len(K_inactivate1)]

T = T_promoter_active * dt

# Histogram and theoretical distribution
bins = np.arange(0, 50 + 1e-3, 1.0)  
fx, x_edges = np.histogram(T, bins=bins)
x = 0.5 * (x_edges[:-1] + x_edges[1:])
px = fx / np.sum(fx) / (bins[1] - bins[0])

plt.figure(102,figsize=(10, 6))
plt.plot(x, px, 'ok', linewidth=2, label='Simulation')
tt = np.linspace(0, 100, 1000)
yy = lambda_E_i * np.exp(-lambda_E_i * tt)
plt.plot(tt, yy, '-g', linewidth=2, label='Simple model')
plt.legend()
plt.xlabel('Duration of enhancer signal on promoter (min)')
plt.ylabel('PDF')
plt.xlim([0, 40])
plt.grid(True)
plt.title('Enhancer Signal Duration Distribution')
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.show()


# Licensed and activated promoter state (burst condition)
J = J1 * J2

# Find activation and inactivation points
diff_J = np.diff(J)
K_activate = np.where(diff_J == 1)[0]    # Points where bursts start
K_inactivate = np.where(diff_J == -1)[0] # Points where bursts end

# Calculate time between activations (T_aa)
T_aa = np.diff(K_activate)

# Handle edge cases where first activation comes before first inactivation
if len(K_activate) > 0 and len(K_inactivate) > 0:
    if K_activate[0] < K_inactivate[0]:
        K_activate = K_activate[1:]

# Initialize output arrays
T_ia = np.array([])
T_ai = np.array([])

if len(K_activate) == len(K_inactivate):
    T_ia = K_activate - K_inactivate
    if len(K_inactivate) > 1:
        T_ai = K_inactivate[1:] - K_activate[:-1]
else:
    if len(K_inactivate) > 0 and len(K_activate) > 0:
        T_ia = K_activate - K_inactivate[:-1]
        if len(K_inactivate) > 1 and len(K_activate) > 0:
            T_ai = K_inactivate[1:] - K_activate[:len(K_inactivate)-1]
  
start_idx = int(len(R_end) - 1e4)
I = np.arange(start_idx, len(R_end))
time_axis = I * dt - I[0] * dt

plt.figure(103,figsize=(10, 5))
plt.plot(time_axis, R_end[I], '.-', label='E-P distance',linewidth=0.5)
plt.plot(time_axis, np.mean(R_end) * np.ones_like(I), '-k', linewidth=2, label='Mean distance')
plt.plot(time_axis, d_c * np.ones_like(I), '--k', linewidth=2, label='Cutoff (d_c)')

plt.xlabel('Time (min)', fontsize=15)
plt.ylabel('E-P distance (μm)', fontsize=15)
plt.legend()
plt.grid(True)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.title('E-P Distance Over Time')
plt.tight_layout()
#plt.xlim([0,100])
plt.show()

# Bursting profile
plt.figure(104)
I = np.arange(len(J) - int(1e4), len(J))
plt.plot(I*dt - I[0]*dt, J[I.astype(int)], '.-b')
plt.xlabel('Time (min)', fontsize=15)
plt.ylabel('Bursting', fontsize=15)
plt.tick_params(axis='both', which='major', labelsize=15)
plt.ylim([0, 1.2])

# Second figure
plt.figure(5, figsize=(18, 6))  

I = np.arange(len(J) - int(0.5e4), len(J))
ii_burst = np.where(J[I.astype(int)] > 0)[0]
jj = np.where(np.diff(ii_burst) > 1)[0]

xx = I * dt - I[0] * dt
X_L = xx[np.concatenate(([ii_burst[0]], ii_burst[jj + 1]))]
X_R = xx[np.concatenate((ii_burst[jj], [ii_burst[-1]]))]

for i in range(len(X_L)):
    x_l = X_L[i]
    x_r = X_R[i]
    plt.fill([x_l, x_r, x_r, x_l], [0, 0, 1, 1], 
             color=(1, 0.5, 0.5), alpha=1)

# Plot R_end data
I = np.arange(len(R_end) - int(0.5e4), len(R_end))
plt.plot(I*dt - I[0]*dt, R_end[I.astype(int)], '-b', linewidth=1.5)
plt.xlabel('Time (min)', fontsize=15)
plt.ylabel('E-P distance (μm)', fontsize=15)

# Plot mean and d_c lines
plt.plot(I*dt - I[0]*dt, np.mean(R_end) * np.ones(len(I)), '-k', linewidth=2)
plt.plot(I*dt - I[0]*dt, d_c * np.ones(len(I)), '--k', linewidth=2)

plt.tick_params(axis='both', which='major', labelsize=15)
plt.ylim([0, 0.8])
plt.box(True)
plt.tight_layout()
plt.show()


rgb_m = np.array([
    [0, 0.4470, 0.7410],
    [0.8500, 0.3250, 0.0980],
    [0.9290, 0.6940, 0.1250],
    [0.4940, 0.1840, 0.5560],
    [0.4660, 0.6740, 0.1880],
    [0.3010, 0.7450, 0.9330],
    [0.6350, 0.0780, 0.1840]
])

cstr = ['o-', 's-', '^-', 'D-']  # circle, square, triangle, diamond
Lon_gb = pd.read_excel(sdir + sfilename, sheet_name='d_E-P(expression_on)').squeeze()
Loff_gb = pd.read_excel(sdir + sfilename, sheet_name='d_E-P(expression_off)').squeeze()

# Histogram settings
bins = np.arange(0, 3 + 0.025, 0.025)
# Figure 7 - Experimental histogram
plt.figure(7, figsize=(7, 5))
for i, L in enumerate([Lon_gb, Loff_gb]):
    fx, _ = np.histogram(L, bins=bins)
    px = fx / np.sum(fx) / (bins[1] - bins[0])
    x = 0.5 * (bins[1:] + bins[:-1])
    plt.plot(x, px, cstr[i][0], color=rgb_m[i], markersize=8,
             linewidth=2, markerfacecolor='none', label=f'Exp {i+1}')
    
plt.xlim([0, 1])
plt.ylim([0, 5])
plt.xlabel('E-P distance (μm)', fontsize=15)
plt.ylabel('Probability Density', fontsize=15)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.legend()
plt.tight_layout()
px_exp = px  # Save for later use

# Create Figure 7 continuation (model vs experiment overlay)
plt.figure(7)
plt.gca().set_position([0.2, 0.2, 0.65, 0.7])
J_bool = np.array(J, dtype=bool)
for i, expr in enumerate([J_bool, ~J_bool]):
    dis = R_end[np.where(expr)]
    fx, _ = np.histogram(dis, bins=bins)
    px = fx / np.sum(fx) / (bins[1] - bins[0])
    x = 0.5 * (bins[1:] + bins[:-1])
    plt.plot(x, px, '-.', linewidth=2, color=rgb_m[i])

plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlim([0, 1])
px0 = px  # Save for later use

# ---- Distance vs. Expression Shift Plot ----
data = pd.read_excel(sdir + sfilename, sheet_name='Dis_Expression_shift', header=None)
tt0 = data.iloc[:, 0]
Dis_gb_ave = data.iloc[:, 1]
Expression_ave = data.iloc[:, 2]

# Figure 9: E-P distance shift
plt.figure(9)
plt.gca().set_position([0.2, 0.2, 0.65, 0.7])
plt.plot(tt0, Dis_gb_ave, 'o', markersize=10, markerfacecolor='w',linewidth=2, color=rgb_m[0])
plt.xlabel('Time (min)', fontsize=15)
plt.ylabel('Mean E-P Distance (μm)', fontsize=15)
plt.grid(True)

# Figure 8: Expression level shift
plt.figure(8)
plt.gca().set_position([0.2, 0.2, 0.3, 0.33])
plt.plot(tt0, Expression_ave, '^', markersize=10, markerfacecolor='w', linewidth=2, color=rgb_m[0])
plt.xlabel('Time (min)', fontsize=15)
plt.ylabel('Expression Level', fontsize=15)
plt.grid(True)

plt.show()

# Initialize arrays
length_shift = int(50 / dt)
d_EP_shift0 = np.zeros(length_shift)
d2_EP_shift0 = np.zeros(length_shift)
n_EP_shift0 = np.zeros(length_shift)
E_shift0 = np.zeros(length_shift)

E1 = 4
E2 = 15.5

for i in range(len(K_activate) - 1):
    ii = np.arange(K_inactivate[i], K_inactivate[i + 1])
    ii2 = ii - K_activate[i] + length_shift // 2 + 1

    # Find valid indices within bounds
    I = np.where((ii2 > 0) & (ii2 <= length_shift))[0]
    
    # Adjust for Python 0-based indexing
    ii_valid = ii[I]
    ii2_valid = ii2[I] - 1  # shift down by 1 for 0-based index

    # Update statistics
    d_EP_shift0[ii2_valid] += R_end[ii_valid]
    d2_EP_shift0[ii2_valid] += R_end[ii_valid] ** 2
    n_EP_shift0[ii2_valid] += 1

    # signal shift update
    E_shift0[ii2_valid] += E1 * J2[ii_valid] + (E2 - E1) * J[ii_valid]
# Normalization
# Preprocessing and normalization
d_EP_shift0 = d_EP_shift0 / n_EP_shift0
d2_EP_shift0 = d2_EP_shift0 / n_EP_shift0
d_EP_shift_sd0 = np.sqrt(d2_EP_shift0 - d_EP_shift0**2)
E_shift0 = E_shift0 / n_EP_shift0

# Find valid indices within range and where Expression_ave is not NaN
I_t = np.where((tt0 >= -10) & (tt0 <= 10) & ~np.isnan(Expression_ave))[0]
tt0_1 = tt0[I_t]
tt = (np.arange(1, len(d_EP_shift0) + 1) - len(d_EP_shift0) / 2 + 1) * dt

I_t1 = []
for t in tt0_1:
    dd = np.abs(tt - t)
    i0 = np.where(dd == np.min(dd))[0]
    I_t1.append(i0[0])

# Output for verification
print("tt:", tt[:5])
print("I_t1:", I_t1[:5])
print("d_EP_shift_sd0:", d_EP_shift_sd0[:5])
print("E_shift0:", E_shift0[:5])

EE1 = np.arange(1, 5.01, 0.5)
EE2 = np.arange(10, 20.01, 0.5)
d0 = 1e10

E1_opt = E1
E2_opt = E2
E_shift0_opt = E_shift0.copy()

n_bins = int(50 / dt)

for E1_test in EE1:
    for E2_test in EE2:
        n_EP_shift0 = np.zeros(n_bins)
        E_shift0_tmp = np.zeros(n_bins)

        for i in range(len(K_activate) - 1):
            ii = np.arange(K_inactivate[i], K_inactivate[i+1])
            ii2 = ii - K_activate[i] + n_bins // 2

            valid = (ii2 >= 0) & (ii2 < len(E_shift0_tmp))
            idx_valid = ii2[valid]

            n_EP_shift0[idx_valid] += 1
            E_shift0_tmp[idx_valid] += E1_test * J2[ii[valid]] + (E2_test - E1_test) * J[ii[valid]]

        with np.errstate(divide='ignore', invalid='ignore'):
            E_shift0_tmp = np.where(n_EP_shift0 > 0, E_shift0_tmp / n_EP_shift0, 0)

        d = np.sqrt(np.sum((E_shift0_tmp[I_t1] - Expression_ave[I_t])**2))

        if d < d0:
            d0 = d
            E1_opt = E1_test
            E2_opt = E2_test
            E_shift0_opt = E_shift0_tmp.copy()

E1 = E1_opt
E2 = E2_opt
E_shift0 = E_shift0_opt

tt = (np.arange(len(d_EP_shift0)) - len(d_EP_shift0)/2 + 1) * dt

# Plotting d_EP_shift0
plt.figure(9)
plt.gca().set_position([0.2, 0.2, 0.65, 0.7])
plt.plot(tt, d_EP_shift0, linestyle='-.', linewidth=2, markersize=10, color=rgb_m[1])
plt.xlabel('Relative time (min)')
plt.ylabel('Average E-P distance (μm)')
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)

# Plotting E_shift0
plt.figure(8)
plt.plot(tt, E_shift0, linestyle='-.', linewidth=3, markersize=10, color=rgb_m[1])
plt.axvline(0, color='k')  # vertical line at t=0
plt.xlabel('t')
plt.ylabel('E')
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.xlim([-10, 10])
plt.ylim([0, 20])
plt.show()

# Initialize variables
T_delay = np.arange(0, 20.5, 0.5)
dd0 = 1e10
delay = 0
px_fit = 0

d_EP_shift_fit = 0
d_EP_shift_sd_fit = 0
E_shift0_fit = 0

tt = (np.arange(1, int(50/dt) + 1) - int(50/dt)/2 + 1) * dt
I_exp = np.where((tt0 >= -10) & (tt0 <= 10))[0]
I_fit = np.zeros(len(I_exp), dtype=int)
for i in range(len(I_exp)):
    A = np.abs(tt - tt0[I_exp[i]])
    j = np.where(A == np.min(A))[0]
    I_fit[i] = j[0]  # use first match

Dis_gb_ave0 = np.max(Dis_gb_ave[I_exp])

bins = np.arange(0, 3.025, 0.025)
ii = np.where(bins < 1)[0]
px_exp0 = np.max(px_exp[ii])

Expression_ave0 = np.max(Expression_ave)

for h in range(1,len(T_delay)):  # T_delay[0]=0
    t_delay = T_delay[h]
    lambda_e = 1 / t_delay
    dd = 0
    px2 = []

    for i in range(2):
        if i == 0:
            ii = np.where(J)[0]
        else:
            ii = np.where(np.logical_not(J))[0]
        
        rr = np.random.rand(len(ii))
        ii_delay = np.floor(-np.log(1 - rr) / lambda_e / dt).astype(int)
        ii_shifted = ii + ii_delay
        ii2 = ii_shifted[ii_shifted < len(R_end)]
        dis = R_end[ii2]

        fx, _ = np.histogram(dis, bins=bins)
        px = fx / np.sum(fx) / (bins[1] - bins[0])
        px2.append(px)
        x = 0.5 * (bins[1:] + bins[:-1])
        dd += np.sqrt(np.sum((px - px_exp) ** 2))

    # Main loop for distance and expression calculation with delay
    d_EP_shift = np.zeros(int(50 / dt))
    d2_EP_shift = np.zeros(int(50 / dt))
    n_EP_shift = np.zeros(int(50 / dt))
    E_shift0 = np.zeros(int(50 / dt))
    n_expression_shift = np.zeros(int(50 / dt))
    rr2 = np.random.rand(len(K_activate))

    ii_delay2 = np.floor(-np.log(1 - rr2) / lambda_e / dt).astype(int)

    for i in range(len(K_activate) - 1):
        i_delay = ii_delay2[i]

        ii = np.arange(K_inactivate[i] + i_delay, min(K_inactivate[i + 1] + i_delay, len(R_end)))
        ii2 = ii - (K_activate[i] + i_delay) + int(len(d_EP_shift) / 2)
        I = np.where((ii2 > 0) & (ii2 < len(d_EP_shift)))[0]
        d_EP_shift[ii2[I]] += R_end[ii[I]]
        d2_EP_shift[ii2[I]] += R_end[ii[I]] ** 2
        n_EP_shift[ii2[I]] += 1

        ii = np.arange(K_inactivate[i], min(K_inactivate[i + 1], len(R_end)))
        ii2 = ii - K_activate[i] + int(len(E_shift0) / 2)
        I = np.where((ii2 > 0) & (ii2 < len(E_shift0)))[0]
        E_shift0[ii2[I]] += E1 * J2[ii[I]] + (E2 - E1) * J[ii[I]]
        n_expression_shift[ii2[I]] += 1

    d_EP_shift = d_EP_shift / n_EP_shift
    d2_EP_shift = d2_EP_shift / n_EP_shift
    d_EP_shift_sd = np.sqrt(d2_EP_shift - d_EP_shift ** 2)
    E_shift0 = E_shift0 / n_expression_shift

    dd += np.sqrt(np.sum((d_EP_shift[I_fit] - Dis_gb_ave[I_exp]) ** 2)) * (px_exp0 / Dis_gb_ave0)
    dd += np.sqrt(np.sum((E_shift0[I_fit] - Expression_ave[I_exp]) ** 2)) * (px_exp0 / Expression_ave0)

    if dd < dd0:
        dd0 = dd
        delay = T_delay[h]
        px_fit = px2
        d_EP_shift_fit = d_EP_shift
        d_EP_shift_sd_fit = d_EP_shift_sd
        E_shift0_fit = E_shift0
# --- Figure 7: Probability Density Plot ---
plt.figure(7)
plt.plot(x, px_fit[0], '.-', linewidth=2, markersize=8,
         markerfacecolor='w', color=rgb_m[0])
plt.plot(x, px_fit[1], '.-', linewidth=2, markersize=8,
         markerfacecolor='w', color=rgb_m[1])
plt.xlabel('E-P distance (μm)')
plt.ylabel('Probability density')
plt.xlim([0, 1.1])
plt.ylim([0, 7.5])
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.gca().tick_params(width=1.5)
plt.legend(['Exp:burst on', 'Exp:burst off', 'Sim:burst on-delay',
            'Sim:burst off-delay', 'Sim:burst on+delay', 'Sim:burst off+delay'])
plt.grid(False)

# --- Figure 9: E-P Distance Over Time ---
plt.figure(9)
tt = (np.arange(len(d_EP_shift_fit)) - len(d_EP_shift_fit)/2 + 1) * dt
plt.plot(tt, d_EP_shift_fit, '.-', markersize=9, linewidth=2, color=rgb_m[1])  # Sim:+delay
plt.axvline(0, color='k')
plt.xlabel('Relative time (min)')
plt.ylabel('Average E-P distance (μm)')
plt.xlim([-10, 10])
plt.ylim([0.22, 0.47])
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.legend(['Exp', 'Sim:-delay', 'Sim:+delay'])
plt.gca().tick_params(width=1.5)

# --- Figure 8: Expression Over Time ---
plt.figure(8)
plt.plot(tt, E_shift0_fit, '.-', markersize=9, linewidth=3, color=rgb_m[1])  # Sim:+delay
plt.axvline(0, color='k')
plt.xlabel('t')
plt.ylabel('E')
plt.xlim([-10, 10])
plt.ylim([0, 20])
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.gca().tick_params(width=1.5)
# plt.legend(['Exp', 'Sim:-delay', 'Sim:+delay'])  # Uncomment if needed        


T_delay = np.zeros(len(K_activate))
for i in range(len(K_activate)):
    ii1 = np.where(K_P_a <= K_activate[i] + 1)[0]
    ii2 = np.where(K_E_a <= K_activate[i] + 1)[0]
    T_delay[i] = (K_E_a[ii2[-1]] - K_P_a[ii1[-1]]) * dt
    
    
# Read Excel data
try:
    T_E_EP = pd.read_excel(f"{sdir}{sfilename}", sheet_name='T_E-EP').values
    T_P_EP = pd.read_excel(f"{sdir}{sfilename}", sheet_name='T_P-EP').values  
    T_P_E = pd.read_excel(f"{sdir}{sfilename}", sheet_name='T_P-E').values
    
    T_E_EP = T_E_EP.flatten()
    T_P_EP = T_P_EP.flatten()
    T_P_E = T_P_E.flatten()    
except Exception as e:
    print(f"Error reading Excel file: {e}")    

####### figure 4
plot_color =rgb_m[0,:]  
for i in range(0,1):  
    fig = plt.figure(4 + i)  
    ax = fig.add_axes([0.2, 0.2, 0.65, 0.7])  # [left, bottom, width, height]    
    # Select the appropriate data
    if i == 0:
        T = T_P_E
    elif i == 1:
        T = T_E_EP
    else:
        T = T_P_EP
    bins = np.linspace(min(T), max(T), 21)  # 20 intervals = 21 edges
    fx, x = np.histogram(T, bins=bins)
    bin_width = x[1] - x[0]
    px = fx / (sum(fx) * bin_width)
    x_centers = (x[:-1] + x[1:]) / 2
    plt.plot(x_centers, px, 'o', markersize=8, markerfacecolor='w', linewidth=2, color=plot_color)
plt.show()    

##
plt.rcParams.update({'font.size': 15})  # Global font size
for i in range(0,1):  
    plt.figure(4 + i)  

    if i == 0:
        T = T_delay
    elif i == 1:
        I = np.where(T_delay < 0)[0]
        T = -T_delay[I]
    else:
        I = np.where(T_delay > 0)[0]
        T = T_delay[I]

    bins = np.arange(-50, 50.5, 2)  
    fx, x = np.histogram(T, bins=bins)
    px = fx / (sum(fx) * (bins[1] - bins[0]))  # Probability density
    
    # Plot histogram
    x_centers = (x[:-1] + x[1:]) / 2  # Use bin centers for plotting
    ax.plot(x_centers, px, '.-', linewidth=2, color=rgb_m[1], markersize=8)
    ax.set_ylabel('Probability density')
    
    # Set plot properties based on i
    if i == 0:
        ax.set_xlabel('Time of E-action relative to P-licensed (min)')
        ax.set_ylim([0, 0.1])
        tt = np.linspace(min(x), max(x), 1000)
        yy = 0.5*lambda_E_i*np.exp(-lambda_E_i*np.abs(tt))*(tt <= 0) + \
             0.5*lambda_P_i*np.exp(-lambda_P_i*tt)*(tt > 0)
    elif i == 1:
        ax.set_xlabel('Delay of E-action relative to P-licensed (min)')
        ax.set_ylim([0, 0.2])
        lambda_ = lambda_E_i
        tt = np.linspace(0, max(x), 1000)
        yy = lambda_ * np.exp(-lambda_ * tt)
    else:
        ax.set_xlabel('Delay of P-licensed relative to E-action (min)')
        ax.set_ylim([0, 0.2])
        lambda_ = lambda_P_i
        tt = np.linspace(0, max(x), 1000)
        yy = lambda_ * np.exp(-lambda_ * tt)
    ax.plot(tt, yy, '.-', linewidth=2, color=rgb_m[4], markersize=8)
    legend =ax.legend(['Experiment', 'Simulation', 'Simple model'])    
    legend.set_draggable(True)  # 启用拖动
    ax.tick_params(width=1.5)  
    for spine in ax.spines.values():
        spine.set_linewidth(1.5)   
    ax.set_xlim([-50, 50])   
plt.show()

###
plt.figure(6)
ax = plt.axes([0.2, 0.2, 0.65, 0.7])  
try:
    T_on_duration_exp = pd.read_excel(f"{sdir}{sfilename}", 
                                    sheet_name='Expression_duration').values.flatten()
except Exception as e:
    print(f"Error reading Excel file: {e}")
    T_on_duration_exp = np.array([]) 

colors = [rgb_m[0], rgb_m[1], rgb_m[4]]  
for i in range(2):  
    if i == 0:
        T = T_on_duration_exp
    else:
        T = T_ai * dt

    bins = np.arange(0, 35.5, 1) 
    fx, x = np.histogram(T, bins=bins)
    px = fx / (sum(fx) * (bins[1] - bins[0])) 
    
    x_centers = (x[:-1] + x[1:]) / 2  # Use bin centers
    if i == 0:
        ax.plot(x_centers, px, 'o', markersize=8, linewidth=2, 
               color=colors[i], label='Experiment')
    else:
        ax.plot(x_centers, px, '-', marker='.', markersize=8, linewidth=2,
               color=colors[i], label='Simulation')
tt = np.arange(0, 100, 0.01)
lambda_tot = lambda_P_i + lambda_E_i
yy = lambda_tot * np.exp(-lambda_tot * tt)
ax.plot(tt, yy, '-', marker='.', markersize=8, linewidth=2,
       color=colors[2], label='Simple model')
ax.set_ylabel('Probability density')
ax.set_xlabel('Burst duration (min)')
ax.set_xlim([0, 15])
ax.tick_params(axis='both', which='major', labelsize=15)
ax.legend(fontsize=12)
for spine in ax.spines.values():
    spine.set_linewidth(1.5)
plt.show()
